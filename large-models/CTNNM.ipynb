{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Circulant Tensor Nuclear Norm Minimization (CTNNM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_mape(var, var_hat):\n",
    "    return np.sum(np.abs(var - var_hat) / var) / var.shape[0]\n",
    "\n",
    "def compute_rmse(var, var_hat):\n",
    "    return np.sqrt(np.sum((var - var_hat) ** 2) / var.shape[0])\n",
    "\n",
    "def prox_2d(z, w, lmbda):\n",
    "    N, T = z.shape\n",
    "    temp1 = np.fft.fft2(lmbda * z - w) / lmbda\n",
    "    temp2 = 1 - N * T / (lmbda * np.abs(temp1))\n",
    "    temp2[temp2 <= 0] = 0\n",
    "    return np.fft.ifft2(temp1 * temp2).real\n",
    "\n",
    "def update_z(y_train, pos_train, x, w, lmbda, eta):\n",
    "    z = x + w / lmbda\n",
    "    z[pos_train] = (lmbda / (lmbda + eta) * z[pos_train] \n",
    "                    + eta / (lmbda + eta) * y_train)\n",
    "    return z\n",
    "\n",
    "def update_w(x, z, w, lmbda):\n",
    "    return w + lmbda * (x - z)\n",
    "\n",
    "def flip_mat(X):\n",
    "    temp = np.append(X, np.flip(X, axis = 1), axis = 1)\n",
    "    return np.append(temp, np.flip(temp, axis = 0), axis = 0)\n",
    "\n",
    "def inv_flip_mat(mat):\n",
    "    dim = mat.shape\n",
    "    N = int(dim[0] / 2)\n",
    "    T = int(dim[1] / 2)\n",
    "    temp = (mat[:, : T] + np.flip(mat[:, T :], axis = 1)) / 2\n",
    "    return (temp[: N, :] + np.flip(temp[N :, :], axis = 0)) / 2\n",
    "\n",
    "def CTNNM(y_true, y, lmbda, maxiter = 50):\n",
    "    dim1, dim2, dim3 = y.shape\n",
    "    eta = 100 * lmbda\n",
    "    if np.isnan(y).any() == False:\n",
    "        pos_test = np.where((y_true != 0) & (y == 0))\n",
    "    elif np.isnan(y).any() == True:\n",
    "        pos_test = np.where((y_true > 0) & (np.isnan(y)))\n",
    "        y[np.isnan(y)] = 0\n",
    "    y_test = y_true[pos_test]\n",
    "    flip_y_true = np.zeros((2 * dim1, 2 * dim2, dim3))\n",
    "    flip_y = np.zeros((2 * dim1, 2 * dim2, dim3))\n",
    "    for t in range(dim3):\n",
    "        flip_y_true[:, :, t] = flip_mat(y_true[:, :, t])\n",
    "        flip_y[:, :, t] = flip_mat(y[:, :, t])\n",
    "    N, T, L = flip_y.shape\n",
    "    pos_train = np.where(flip_y != 0)\n",
    "    y_train = flip_y[pos_train]\n",
    "    z = flip_y.copy()\n",
    "    w = flip_y.copy()\n",
    "    del y_true, y\n",
    "    show_iter = 10\n",
    "    for it in range(maxiter):\n",
    "        x = np.zeros((N, T, L))\n",
    "        for t in range(dim3):\n",
    "            x[:, :, t] = prox_2d(z[:, :, t], w[:, :, t], lmbda)\n",
    "        z = update_z(y_train, pos_train, x, w, lmbda, eta)\n",
    "        w = update_w(x, z, w, lmbda)\n",
    "        y_hat = np.zeros((dim1, dim2, dim3))\n",
    "        for t in range(dim3):\n",
    "            y_hat[:, :, t] = inv_flip_mat(x[:, :, t])\n",
    "        if (it + 1) % show_iter == 0:\n",
    "            print(it + 1)\n",
    "            print(compute_mape(y_test, y_hat[pos_test]))\n",
    "            print(compute_rmse(y_test, y_hat[pos_test]))\n",
    "            print()\n",
    "    return y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Large Time Series Imputation\n",
    "\n",
    "PeMS dataset is available at https://github.com/xinychen/transdim/tree/master/datasets/California-data-set.\n",
    "\n",
    "Hyperparameter:\n",
    "\n",
    "- $\\lambda=10^{-5}NT$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1000)\n",
    "\n",
    "dense_mat = np.load('pems-w1.npz')['arr_0']\n",
    "for t in range(2, 5):\n",
    "    dense_mat = np.append(dense_mat, np.load('pems-w{}.npz'.format(t))['arr_0'],\n",
    "                          axis = 1)\n",
    "dim1, dim2 = dense_mat.shape\n",
    "\n",
    "missing_rate = 0.9\n",
    "sparse_mat = dense_mat * np.round(np.random.rand(dim1, dim2) + 0.5 - missing_rate)\n",
    "# np.savez_compressed('dense_mat.npz', dense_mat)\n",
    "# np.savez_compressed('sparse_mat.npz', sparse_mat)\n",
    "\n",
    "# import cupy as np\n",
    "\n",
    "# dense_mat = np.load('dense_mat.npz')['arr_0']\n",
    "# sparse_mat = np.load('sparse_mat.npz')['arr_0']\n",
    "\n",
    "import time\n",
    "start = time.time()\n",
    "N, T = sparse_mat.shape\n",
    "lmbda = 1e-5 * N * T\n",
    "maxiter = 100\n",
    "tensor_hat = CTNNM(dense_mat, sparse_mat, lmbda, maxiter)\n",
    "end = time.time()\n",
    "print('Running time: %d seconds.'%(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### License\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>This work is released under the MIT license.</b>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
