{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laplacian Convolutional Representation (LCR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_mape(var, var_hat):\n",
    "    return np.sum(np.abs(var - var_hat) / var) / var.shape[0]\n",
    "\n",
    "def compute_rmse(var, var_hat):\n",
    "    return np.sqrt(np.sum((var - var_hat) ** 2) / var.shape[0])\n",
    "\n",
    "def laplacian(T, tau):\n",
    "    ell = np.zeros(T)\n",
    "    ell[0] = 2 * tau\n",
    "    for k in range(tau):\n",
    "        ell[k + 1] = -1\n",
    "        ell[-k - 1] = -1\n",
    "    return ell\n",
    "\n",
    "def prox_2d(z, w, lmbda, denominator):\n",
    "    N, T = z.shape\n",
    "    temp1 = np.fft.fft2(lmbda * z - w) / denominator\n",
    "    temp2 = 1 - N * T / (denominator * np.abs(temp1))\n",
    "    temp2[temp2 <= 0] = 0\n",
    "    return np.fft.ifft2(temp1 * temp2).real\n",
    "\n",
    "def update_z(y_train, pos_train, x, w, lmbda, eta):\n",
    "    z = x + w / lmbda\n",
    "    z[pos_train] = (lmbda / (lmbda + eta) * z[pos_train] \n",
    "                    + eta / (lmbda + eta) * y_train)\n",
    "    return z\n",
    "\n",
    "def update_w(x, z, w, lmbda):\n",
    "    return w + lmbda * (x - z)\n",
    "\n",
    "def LCR_2d(y_true, y, lmbda, gamma, tau_s, tau_t, maxiter = 50):\n",
    "    eta = 100 * lmbda\n",
    "    if np.isnan(y).any() == False:\n",
    "        pos_test = np.where((y_true != 0) & (y == 0))\n",
    "    elif np.isnan(y).any() == True:\n",
    "        pos_test = np.where((y_true > 0) & (np.isnan(y)))\n",
    "        y[np.isnan(y)] = 0\n",
    "    y_test = y_true[pos_test]\n",
    "    pos_train = np.where(y != 0)\n",
    "    y_train = y[pos_train]\n",
    "    z = y.copy()\n",
    "    w = y.copy()\n",
    "    ell_s = np.zeros(N)\n",
    "    ell_s[0] = 1\n",
    "    # ell_s = laplacian(N, tau_s)\n",
    "    ell_t = laplacian(T, tau_t)\n",
    "    ell = np.fft.fft2(np.outer(ell_s, ell_t))\n",
    "    denominator = lmbda + gamma * np.abs(ell) ** 2\n",
    "    del y_true, y\n",
    "    show_iter = 10\n",
    "    for it in range(maxiter):\n",
    "        x = prox_2d(z, w, lmbda, denominator)\n",
    "        z = update_z(y_train, pos_train, x, w, lmbda, eta)\n",
    "        w = update_w(x, z, w, lmbda)\n",
    "        if (it + 1) % show_iter == 0:\n",
    "            print(it + 1)\n",
    "            print(compute_mape(y_test, x[pos_test]))\n",
    "            print(compute_rmse(y_test, x[pos_test]))\n",
    "            print()\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Large Time Series Imputation\n",
    "\n",
    "PeMS dataset is available at https://github.com/xinychen/transdim/tree/master/datasets/California-data-set.\n",
    "\n",
    "Hyperparameters:\n",
    "\n",
    "- On 30%/50% missing data, $\\lambda=10^{-5}NT$, $\\gamma=10\\lambda$, and $\\tau=1$;\n",
    "- On 70% missing data, $\\lambda=10^{-5}NT$, $\\gamma=10\\lambda$, and $\\tau=2$;\n",
    "- On 90% missing data, $\\lambda=10^{-5}NT$, $\\gamma=10\\lambda$, and $\\tau=3$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1000)\n",
    "\n",
    "dense_mat = np.load('pems-w1.npz')['arr_0']\n",
    "for t in range(2, 5):\n",
    "    dense_mat = np.append(dense_mat, np.load('pems-w{}.npz'.format(t))['arr_0'],\n",
    "                          axis = 1)\n",
    "dim1, dim2 = dense_mat.shape\n",
    "\n",
    "missing_rate = 0.9\n",
    "sparse_mat = dense_mat * np.round(np.random.rand(dim1, dim2) + 0.5 - missing_rate)\n",
    "# np.savez_compressed('dense_mat.npz', dense_mat)\n",
    "# np.savez_compressed('sparse_mat.npz', sparse_mat)\n",
    "\n",
    "# import cupy as np\n",
    "\n",
    "# dense_mat = np.load('dense_mat.npz')['arr_0']\n",
    "# sparse_mat = np.load('sparse_mat.npz')['arr_0']\n",
    "\n",
    "import time\n",
    "start = time.time()\n",
    "N, T = sparse_mat.shape\n",
    "lmbda = 1e-5 * N * T\n",
    "gamma = 10 * lmbda\n",
    "tau_s = 1\n",
    "tau_t = 3\n",
    "maxiter = 100\n",
    "mat_hat = LCR_2d(dense_mat, sparse_mat, lmbda, gamma, tau_s, tau_t, maxiter)\n",
    "end = time.time()\n",
    "print('Running time: %d seconds.'%(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### License\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>This work is released under the MIT license.</b>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
